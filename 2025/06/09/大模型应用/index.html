<!DOCTYPE html>


<html theme="dark" showBanner="true" hasBanner="true" > 
<link href="https://cdn.staticfile.org/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet">
<link href="https://cdn.staticfile.org/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet">
<link href="https://cdn.staticfile.org/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet">
<script src="/js/color.global.min.js" ></script>
<script src="/js/load-settings.js" ></script>
<head>
  <meta charset="utf-8">
  
  
  

  
  <title>大模型应用 | 季禾子寒舍</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="preload" href="/css/fonts/Roboto-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous">
  <link rel="preload" href="/css/fonts/Roboto-Bold.ttf" as="font" type="font/ttf" crossorigin="anonymous">

  <meta name="description" content="大模型应用7.1 LLM 的评测近年来，随着人工智能领域的迅猛发展，大规模预训练语言模型（简称大模型）成为了推动技术进步的核心力量。这些大模型在自然语言处理等任务中展现出了令人惊叹的能力。然而，要准确衡量一个大模型的性能，必须依靠科学而合理的评测。 什么是大模型评测？大模型评测就是通过各种标准化的方法和数据集，对大模型在不同任务上的表现进行量化和比较。这些评测不仅包括模型在特定任务上的准确性，还涉">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型应用">
<meta property="og:url" content="https://kouirwu.github.io/2025/06/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/index.html">
<meta property="og:site_name" content="季禾子寒舍">
<meta property="og:description" content="大模型应用7.1 LLM 的评测近年来，随着人工智能领域的迅猛发展，大规模预训练语言模型（简称大模型）成为了推动技术进步的核心力量。这些大模型在自然语言处理等任务中展现出了令人惊叹的能力。然而，要准确衡量一个大模型的性能，必须依靠科学而合理的评测。 什么是大模型评测？大模型评测就是通过各种标准化的方法和数据集，对大模型在不同任务上的表现进行量化和比较。这些评测不仅包括模型在特定任务上的准确性，还涉">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-1-Open%20LLM%20Leaderboard.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-1-lmsys%20Chatbot%20Arena%20Leaderboard.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-1-opencompass.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-1-%E5%9E%82%E7%9B%B4%E9%A2%86%E5%9F%9F%E6%A6%9C%E5%8D%95.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-2-tinyrag.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-2-rag.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-3-Agent%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-3-tinyagent-example.png">
<meta property="og:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-3-Tiny_Agent.jpg">
<meta property="article:published_time" content="2025-06-09T09:03:32.000Z">
<meta property="article:modified_time" content="2025-06-09T09:07:19.607Z">
<meta property="article:author" content="Kouir Wu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kouirwu.github.io/2025/06/09/images/7-images/7-1-Open%20LLM%20Leaderboard.png">
  
    <link rel="alternate" href="/atom.xml" title="季禾子寒舍" type="application/atom+xml">
  
  
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-32.png" sizes="32x32">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-128.png" sizes="128x128">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-180.png" sizes="180x180">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-192.png" sizes="192x192">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-32.png" sizes="32x32">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-128.png" sizes="128x128">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-180.png" sizes="180x180">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-192.png" sizes="192x192">
  
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  
  
    
<div id="banner" class="">
  <img src="/images/background.jpg" itemprop="image">
  <div id="banner-dim"></div>
</div>
 
   
  <div id="main-grid" class="  ">
    <div id="nav" class=""  >
      <navbar id="navbar">
  <nav id="title-nav">
    <a href="/">
      <div id="vivia-logo">
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
      </div>
      <div>季禾子寒舍 </div>
    </a>
  </nav>
  <nav id="main-nav">
    
      <a class="main-nav-link" href="/">主页</a>
    
      <a class="main-nav-link" href="/leetcode">Leetcode指南</a>
    
      <a class="main-nav-link" href="/machine_learning">机器学习</a>
    
      <a class="main-nav-link" href="/archives">归档</a>
    
      <a class="main-nav-link" href="/about">关于我</a>
    
  </nav>
  <nav id="sub-nav">
    <a id="theme-btn" class="nav-icon">
      <span class="light-mode-icon"><svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M438.5-829.913v-48q0-17.452 11.963-29.476 11.964-12.024 29.326-12.024 17.363 0 29.537 12.024t12.174 29.476v48q0 17.452-11.963 29.476-11.964 12.024-29.326 12.024-17.363 0-29.537-12.024T438.5-829.913Zm0 747.826v-48q0-17.452 11.963-29.476 11.964-12.024 29.326-12.024 17.363 0 29.537 12.024t12.174 29.476v48q0 17.452-11.963 29.476-11.964 12.024-29.326 12.024-17.363 0-29.537-12.024T438.5-82.087ZM877.913-438.5h-48q-17.452 0-29.476-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537t29.476-12.174h48q17.452 0 29.476 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T877.913-438.5Zm-747.826 0h-48q-17.452 0-29.476-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537T82.087-521.5h48q17.452 0 29.476 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T130.087-438.5Zm660.174-290.87-34.239 32q-12.913 12.674-29.565 12.174-16.653-.5-29.327-13.174-12.674-12.673-12.554-28.826.12-16.152 12.794-28.826l33-35q12.913-12.674 30.454-12.674t30.163 12.847q12.709 12.846 12.328 30.826-.38 17.98-13.054 30.653ZM262.63-203.978l-32 34q-12.913 12.674-30.454 12.674t-30.163-12.847q-12.709-12.846-12.328-30.826.38-17.98 13.054-30.653l33.239-31q12.913-12.674 29.565-12.174 16.653.5 29.327 13.174 12.674 12.673 12.554 28.826-.12 16.152-12.794 28.826Zm466.74 33.239-32-33.239q-12.674-12.913-12.174-29.565.5-16.653 13.174-29.327 12.673-12.674 28.826-13.054 16.152-.38 28.826 12.294l35 33q12.674 12.913 12.674 30.454t-12.847 30.163q-12.846 12.709-30.826 12.328-17.98-.38-30.653-13.054ZM203.978-697.37l-34-33q-12.674-12.913-13.174-29.945-.5-17.033 12.174-29.707t31.326-13.293q18.653-.62 31.326 13.054l32 34.239q11.674 12.913 11.174 29.565-.5 16.653-13.174 29.327-12.673 12.674-28.826 12.554-16.152-.12-28.826-12.794ZM480-240q-100 0-170-70t-70-170q0-100 70-170t170-70q100 0 170 70t70 170q0 100-70 170t-170 70Zm-.247-82q65.703 0 111.475-46.272Q637-414.544 637-480.247t-45.525-111.228Q545.95-637 480.247-637t-111.475 45.525Q323-545.95 323-480.247t45.525 111.975Q414.05-322 479.753-322ZM481-481Z"/></svg></span>
      <span class="dark-mode-icon"><svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M480.239-116.413q-152.63 0-258.228-105.478Q116.413-327.37 116.413-480q0-130.935 77.739-227.435t206.304-125.043q43.022-9.631 63.87 10.869t3.478 62.805q-8.891 22.043-14.315 44.463-5.424 22.42-5.424 46.689 0 91.694 64.326 155.879 64.325 64.186 156.218 64.186 24.369 0 46.978-4.946 22.609-4.945 44.413-14.076 42.826-17.369 62.967 1.142 20.142 18.511 10.511 61.054Q807.174-280 712.63-198.206q-94.543 81.793-232.391 81.793Zm0-95q79.783 0 143.337-40.217 63.554-40.218 95.793-108.283-15.608 4.044-31.097 5.326-15.49 1.283-31.859.805-123.706-4.066-210.777-90.539-87.071-86.473-91.614-212.092-.24-16.369.923-31.978 1.164-15.609 5.446-30.978-67.826 32.478-108.282 96.152Q211.652-559.543 211.652-480q0 111.929 78.329 190.258 78.329 78.329 190.258 78.329ZM466.13-465.891Z"/></svg></span>
    </a>
    
      <a id="nav-rss-link" class="nav-icon mobile-hide" href="/atom.xml" title="RSS 订阅">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M198-120q-25.846 0-44.23-18.384-18.384-18.385-18.384-44.23 0-25.846 18.384-44.23 18.384-18.385 44.23-18.385 25.846 0 44.23 18.385 18.384 18.384 18.384 44.23 0 25.845-18.384 44.23Q223.846-120 198-120Zm538.385 0q-18.846 0-32.923-13.769-14.076-13.769-15.922-33.23-8.692-100.616-51.077-188.654-42.385-88.039-109.885-155.539-67.5-67.501-155.539-109.885Q283-663.462 182.385-672.154q-19.461-1.846-33.23-16.23-13.769-14.385-13.769-33.846t14.076-32.922q14.077-13.461 32.923-12.23 120.076 8.692 226.038 58.768 105.961 50.077 185.73 129.846 79.769 79.769 129.846 185.731 50.077 105.961 58.769 226.038 1.231 18.846-12.538 32.922Q756.461-120 736.385-120Zm-252 0q-18.231 0-32.423-13.461t-18.653-33.538Q418.155-264.23 348.886-333.5q-69.27-69.27-166.501-84.423-20.077-4.462-33.538-18.961-13.461-14.5-13.461-33.346 0-19.076 13.884-33.23 13.884-14.153 33.115-10.922 136.769 15.384 234.384 112.999 97.615 97.615 112.999 234.384 3.231 19.23-10.538 33.115Q505.461-120 484.385-120Z"/></svg>
      </a>
    
    <div id="nav-menu-btn" class="nav-icon">
      <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M177.37-252.282q-17.453 0-29.477-11.964-12.024-11.963-12.024-29.326t12.024-29.537q12.024-12.174 29.477-12.174h605.26q17.453 0 29.477 11.964 12.024 11.963 12.024 29.326t-12.024 29.537q-12.024 12.174-29.477 12.174H177.37Zm0-186.218q-17.453 0-29.477-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537T177.37-521.5h605.26q17.453 0 29.477 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T782.63-438.5H177.37Zm0-186.217q-17.453 0-29.477-11.964-12.024-11.963-12.024-29.326t12.024-29.537q12.024-12.174 29.477-12.174h605.26q17.453 0 29.477 11.964 12.024 11.963 12.024 29.326t-12.024 29.537q-12.024 12.174-29.477 12.174H177.37Z"/></svg>
    </div>
  </nav>
</navbar>
<div id="nav-dropdown" class="hidden">
  <div id="dropdown-link-list">
    
      <a class="nav-dropdown-link" href="/">主页</a>
    
      <a class="nav-dropdown-link" href="/leetcode">Leetcode指南</a>
    
      <a class="nav-dropdown-link" href="/machine_learning">机器学习</a>
    
      <a class="nav-dropdown-link" href="/archives">归档</a>
    
      <a class="nav-dropdown-link" href="/about">关于我</a>
    
    
      <a class="nav-dropdown-link" href="/atom.xml" title="RSS 订阅">RSS</a>
     
    </div>
</div>
<script>
  let dropdownBtn = document.getElementById("nav-menu-btn");
  let dropdownEle = document.getElementById("nav-dropdown");
  dropdownBtn.onclick = function() {
    dropdownEle.classList.toggle("hidden");
  }
</script>
    </div>
    <div id="sidebar-wrapper">
      <sidebar id="sidebar">
  
    <div class="widget-wrap">
  <div class="info-card">
    <div class="avatar">
      
        <image src=/images/touxiang.jpg></image>
      
      <div class="img-dim"></div>
    </div>
    <div class="info">
      <div class="username">Kouir Wu </div>
      <div class="dot"></div>
      <div class="subtitle">当你深处深渊，退无可退的时候，眼前只剩下向上的一条路。 </div>
      <div class="link-list">
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://twitter.com" title="Twitter"><i class="fa-brands fa-twitter"></i></a>
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://github.com/KouirWu" title="GitHub"><i class="fa-brands fa-github"></i></a>
         
      </div>  
    </div>
  </div>
</div>

  
  <div class="sticky">
    
      
  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">分类</h3>
      <div class="category-box">
            <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/">
                机器学习实战
                <div class="category-count">1</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/Titanic/">
                Titanic
                <div class="category-count">1</div>
            </a>
        </div></div>
            <a class="category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                人工智能
                <div class="category-count">1</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Trae-AI/">
                Trae AI
                <div class="category-count">1</div>
            </a>
        </div></div>
            <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/">
                前端开发
                <div class="category-count">3</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/Vue3/">
                Vue3
                <div class="category-count">3</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/Vue3/%E5%B0%8F%E5%85%94%E9%B2%9C/">
                小兔鲜
                <div class="category-count">2</div>
            </a>
        
            <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/Vue3/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/">
                问题解决
                <div class="category-count">1</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/Vue3/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/vue3%E9%99%AA%E8%AF%8A%E7%B3%BB%E7%BB%9F/">
                vue3陪诊系统
                <div class="category-count">1</div>
            </a>
        </div></div></div></div></div></div>
            <a class="category-link" href="/categories/Deepseek/">
                Deepseek
                <div class="category-count">2</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/Deepseek/Linux/">
                Linux
                <div class="category-count">2</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/Deepseek/Linux/Ollama/">
                Ollama
                <div class="category-count">2</div>
            </a>
        </div></div></div></div>
            <a class="category-link" href="/categories/leetcode/">
                leetcode
                <div class="category-count">4</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/leetcode/hot100/">
                hot100
                <div class="category-count">4</div>
            </a>
        </div></div>
            <a class="category-link" href="/categories/LLM%E5%A4%A7%E6%A8%A1%E5%9E%8B/">
                LLM大模型
                <div class="category-count">3</div>
            </a>
        
            <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                机器学习
                <div class="category-count">1</div>
            </a>
        <div class="children" style="display: none;"><div class="category-box">
            <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">
                环境配置
                <div class="category-count">1</div>
            </a>
        </div></div></div>
    </div>
  </div>
  <script>
    document.querySelectorAll('.category-link').forEach(link => {
      link.addEventListener('click', function(e) {
        const children = this.nextElementSibling;
        if (children && children.classList.contains('children')) {
          e.preventDefault();
          if (children.style.display === 'none') {
            children.style.display = 'block';
          } else {
            children.style.display = 'none';
          }
        }
      });
    });
    // 设置初始状态为折叠状态
    document.querySelectorAll('.children').forEach(children => {
      children.style.display = 'none';
    });
  </script>


    
      
  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">标签</h3>
      <ul class="widget-tag-list" itemprop="keywords"><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Deepseek/" rel="tag">Deepseek</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Element-Plus/" rel="tag">Element Plus</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Kaggle/" rel="tag">Kaggle</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/MCP/" rel="tag">MCP</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Ollama/" rel="tag">Ollama</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Titanic/" rel="tag">Titanic</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Trae-AI/" rel="tag">Trae AI</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Vue3/" rel="tag">Vue3</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/vue3%E9%99%AA%E8%AF%8A%E7%B3%BB%E7%BB%9F/" rel="tag">vue3陪诊系统</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/" rel="tag">前端开发</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/" rel="tag">双指针</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" rel="tag">哈希表</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" rel="tag">字符串</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%B0%8F%E5%85%94%E9%B2%9C/" rel="tag">小兔鲜</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%B0%8F%E7%99%BD%E6%95%99%E7%A8%8B/" rel="tag">小白教程</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" rel="tag">并查集</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%8E%92%E5%BA%8F/" rel="tag">排序</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" rel="tag">环境搭建</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E9%85%8D%E7%BD%AE/" rel="tag">配置</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/" rel="tag">问题解决</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">最新文章</h3>
      <ul>
        
          <a class="recent-link" href="/2025/06/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/" title="大模型应用" >
            <div class="recent-link-text">
              大模型应用
            </div>
          </a>
        
          <a class="recent-link" href="/2025/06/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E5%AE%9E%E8%B7%B5/" title="大模型训练流程实践" >
            <div class="recent-link-text">
              大模型训练流程实践
            </div>
          </a>
        
          <a class="recent-link" href="/2025/06/09/%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="动手搭建大模型" >
            <div class="recent-link-text">
              动手搭建大模型
            </div>
          </a>
        
          <a class="recent-link" href="/2025/06/06/hot100%E7%A7%BB%E5%8A%A8%E9%9B%B6/" title="✨ LeetCode Hot 100 - 283. 移动零 ✨" >
            <div class="recent-link-text">
              ✨ LeetCode Hot 100 - 283. 移动零 ✨
            </div>
          </a>
        
          <a class="recent-link" href="/2025/06/06/hot100%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/" title="✨ LeetCode Hot 100 - 128. 最长连续序列 ✨" >
            <div class="recent-link-text">
              ✨ LeetCode Hot 100 - 128. 最长连续序列 ✨
            </div>
          </a>
        
      </ul>
    </div>
  </div>

    
  </div>
</sidebar>
    </div>
    <div id="content-body">
       


<article id="post-大模型应用" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
    
   
  <div class="article-inner">
    <div class="article-main">
      <header class="article-header">
        
<div class="main-title-bar">
  <div class="main-title-dot"></div>
  
    
      <h1 class="p-name article-title" itemprop="headline name">
        大模型应用
      </h1>
    
  
</div>

        <div class='meta-info-bar'>
          <div class="meta-info">
  <time class="dt-published" datetime="2025-06-09T09:03:32.000Z" itemprop="datePublished">2025-06-09</time>
</div>
          <div class="need-seperator meta-info">
            <div class="meta-cate-flex">
  
  <a class="meta-cate-link" href="/categories/LLM%E5%A4%A7%E6%A8%A1%E5%9E%8B/">LLM大模型</a>
   
</div>
  
          </div>
          <div class="wordcount need-seperator meta-info">
            20k 词 
          </div>
        </div>
        
      </header>
      <div class="e-content article-entry" itemprop="articleBody">
        
          <h1 id="大模型应用"><a href="#大模型应用" class="headerlink" title="大模型应用"></a>大模型应用</h1><h2 id="7-1-LLM-的评测"><a href="#7-1-LLM-的评测" class="headerlink" title="7.1 LLM 的评测"></a>7.1 LLM 的评测</h2><p>近年来，随着人工智能领域的迅猛发展，大规模预训练语言模型（简称大模型）成为了推动技术进步的核心力量。这些大模型在自然语言处理等任务中展现出了令人惊叹的能力。然而，要准确衡量一个大模型的性能，必须依靠科学而合理的评测。</p>
<p>什么是大模型评测？大模型评测就是通过各种标准化的方法和数据集，对大模型在不同任务上的表现进行量化和比较。这些评测不仅包括模型在特定任务上的准确性，还涉及模型的泛化能力、推理速度、资源消耗等多个方面。通过评测，我们能够更全面地了解大模型的实际表现，以及它们在现实世界中的应用潜力。</p>
<p>大模型的开发成本高昂，涉及大量的计算资源和数据，因此评测对于确保模型的实际价值至关重要。首先，评测能够揭示模型在各种任务中的表现，帮助研究人员和企业判断模型的适用性和可靠性。其次，评测可以暴露模型的潜在弱点，例如偏见、鲁棒性问题等，从而为进一步优化和改进提供依据。此外，公平、公开的评测还为学术界和工业界提供了一个共同的标准，促进了技术的交流与进步。</p>
<h3 id="7-1-1-LLM-的评测数据集"><a href="#7-1-1-LLM-的评测数据集" class="headerlink" title="7.1.1 LLM 的评测数据集"></a>7.1.1 LLM 的评测数据集</h3><p>在大模型的评测过程中，使用标准化的评测集至关重要。目前，主流的大模型评测集主要从以下几个方面进行评估，每个评测集都有其独特的用途和典型应用场景：</p>
<ol>
<li><p><strong>通用评测集</strong>：</p>
<ul>
<li><strong>MMLU（Massive Multitask Language Understanding）</strong>：MMLU评测模型在多种任务中的理解能力，包括各类学科和知识领域。具体包含了历史、数学、物理、生物、法律等任务类型，全面考察模型在不同学科的知识储备和语言理解能力。</li>
</ul>
</li>
<li><p><strong>工具使用评测集</strong>：</p>
<ul>
<li><strong>BFCL V2</strong>：用于评测模型在复杂工具使用任务中的表现，特别是在执行多步骤操作时的正确性和效率。这些任务通常涉及与数据库交互或执行特定指令，以模拟实际工具使用场景。</li>
<li><strong>Nexus</strong>：用于测试模型在多步骤操作中的工具使用能力，主要评估其在多任务操作中的协调性和任务管理能力，如进行文件操作、数据整合等复杂流程。</li>
</ul>
</li>
<li><p><strong>数学评测集</strong>：</p>
<ul>
<li><strong>GSM8K</strong>：GSM8K是一个包含小学数学问题的数据集，用于测试模型的数学推理和逻辑分析能力。具体任务包括算术运算、简单方程求解、数字推理等。GSM8K中的问题虽然看似简单，但模型需要理解问题语义并进行正确的数学运算，体现了逻辑推理和语言理解的双重挑战。</li>
<li><strong>MATH</strong>：MATH数据集用于测试模型在更复杂的数学问题上的表现，包括代数和几何。</li>
</ul>
</li>
<li><p><strong>推理评测集</strong>：</p>
<ul>
<li><strong>ARC Challenge</strong>：ARC Challenge评测模型在科学推理任务中的表现，尤其是常识性和科学性问题的解答，典型应用场景包括科学考试题解答和百科问答系统的开发。</li>
<li><strong>GPQA</strong>：用于评测模型在零样本条件下对开放性问题的回答能力，通常应用于客服聊天机器人和知识问答系统中，帮助模型在缺乏特定领域数据的情况下给出合理的回答。</li>
<li><strong>HellaSwag</strong>：评测模型在复杂语境下选择最符合逻辑的答案的能力，适用于故事续写、对话生成等需要高水平理解和推理的场景。</li>
</ul>
</li>
<li><p><strong>长文本理解评测集</strong>：</p>
<ul>
<li><strong>InfiniteBench&#x2F;En.MC</strong>：评测模型在处理长文本阅读理解方面的能力，尤其是对科学文献的理解，适用于学术文献自动摘要、长篇报道分析等应用场景。</li>
<li><strong>NIH&#x2F;Multi-needle</strong>：用于测试模型在多样本长文档环境中的理解和总结能力，应用于政府报告解读、企业内部长文档分析等需要处理海量信息的场景。</li>
</ul>
</li>
<li><p><strong>多语言评测集</strong>：</p>
<ul>
<li><strong>MGSM</strong>：用于评估模型在不同语言下的数学问题解决能力，考察模型的多语言适应性，尤其适用于国际化环境中的数学教育和跨语言技术支持场景。</li>
</ul>
</li>
</ol>
<p>这些评测集的多样性帮助我们全面评估大模型在不同任务和应用场景中的表现，确保模型在处理多样化任务时能够保持高效和精准的表现。例如，在MMLU评测中，某些大模型在历史、物理等学科任务中表现优异，展现出对多领域知识的深度理解；在GSM8K数学评测中，最新的大模型在算术和方程求解方面表现接近甚至超越了一些人类基准，显示出在复杂数学推理任务中的潜力。这些实际评测结果展示了模型在各类复杂任务中的进步和应用潜力。</p>
<h3 id="7-1-2-主流的评测榜单"><a href="#7-1-2-主流的评测榜单" class="headerlink" title="7.1.2 主流的评测榜单"></a>7.1.2 主流的评测榜单</h3><p>大模型的评测不仅限于使用特定的数据集，许多机构还会根据评测结果发布模型排行榜，这些榜单为学术界和工业界提供了重要的参考，帮助他们了解当前最前沿的技术和模型。以下是一些主流的评测榜单：</p>
<h4 id="Open-LLM-Leaderboard"><a href="#Open-LLM-Leaderboard" class="headerlink" title="Open LLM Leaderboard"></a>Open LLM Leaderboard</h4><p>Open LLM Leaderboard 为由 Hugging Face 提供的开放式榜单，汇集了多个开源大模型的评测结果，帮助用户了解不同模型在各种任务上的表现。该榜单通过多个标准化测试集来评估模型的性能，并通过持续更新的方式反映最新的技术进展，为研究者和开发者提供了高价值的对比参考，如图7.1所示。</p>
<div align='center'>
    <img src="../images/7-images/7-1-Open%20LLM%20Leaderboard.png" alt="alt text" width="90%">
    <p>图 7.1 Open LLM Leaderboard</p>
</div>

<h4 id="Lmsys-Chatbot-Arena-Leaderboard"><a href="#Lmsys-Chatbot-Arena-Leaderboard" class="headerlink" title="Lmsys Chatbot Arena Leaderboard"></a>Lmsys Chatbot Arena Leaderboard</h4><p>由lmsys提供的聊天机器人评测榜单，通过多维度的评估，展示各类大模型在对话任务中的能力。该榜单采用真实用户与模型交互的方式来评测对话质量，重点考察模型的自然语言生成能力、上下文理解能力以及用户满意度，是当前评估聊天机器人性能的重要工具，如图7.2所示。</p>
<div align='center'>
    <img src="../images/7-images/7-1-lmsys%20Chatbot%20Arena%20Leaderboard.png" alt="alt text" width="90%">
    <p>图7.2 Lmsys Chatbot Arena Leaderboard</p>
</div>

<h4 id="OpenCompass"><a href="#OpenCompass" class="headerlink" title="OpenCompass"></a>OpenCompass</h4><p>OpenCompass 是国内的评测榜单，针对大模型在多种语言和任务上的表现进行评估，提供了中国市场特定应用的参考。该榜单结合了中文语言理解和多语言能力的测试，以适应本地化需求，并特别关注大模型在中文语境下的准确性、鲁棒性和适应性，为国内企业和研究者选择合适的模型提供了重要参考。</p>
<div align='center'>
    <img src="../images/7-images/7-1-opencompass.png" alt="alt text" width="90%">
    <p>图7.3 OpenCompass</p>
</div>

<h3 id="7-1-3-特定的评测榜单"><a href="#7-1-3-特定的评测榜单" class="headerlink" title="7.1.3 特定的评测榜单"></a>7.1.3 特定的评测榜单</h3><p>另外，还有针对不同领域特定任务的大模型评测榜单，如图7.4所示。这些榜单专注于特定应用领域，帮助用户了解大模型在某一垂直领域的能力：</p>
<ul>
<li><p>金融榜：基于CFBenchmark评测集，评估大模型在金融自然语言处理、金融预测计算、金融分析与安全检查等多项基础任务中的能力。由同济大学与上海人工智能实验室及东方财经提供。</p>
</li>
<li><p>安全榜：基于Flames评测集，评估大模型在公平、安全、数据保护以及合法五大维度的抗性，帮助深入了解模型在安全性上的表现。由上海人工智能实验室与复旦大学提供。</p>
</li>
<li><p>通识榜：基于BotChat评测集，评估大语言模型生成日常多轮对话能力的综合程度，判断模型在对话中是否具备类人水平。由上海人工智能实验室提供。</p>
</li>
<li><p>法律榜：基于LawBench评测集，评估模型在法律领域的理解、推理和应用能力，涵盖法律问题回答、文本生成、法律判例分析等任务。由南京大学提供。</p>
</li>
<li><p>医疗榜：基于MedBench评测集，评估大语言模型在医学知识问答、安全伦理理解等方面的表现。由上海人工智能实验室提供。</p>
</li>
</ul>
<div align='center'>
    <img src="../images/7-images/7-1-垂直领域榜单.png" alt="alt text" width="90%">
    <p>图7.4 垂直领域榜单</p>
</div>


<h2 id="7-2-RAG"><a href="#7-2-RAG" class="headerlink" title="7.2 RAG"></a>7.2 RAG</h2><h3 id="7-2-1-RAG-的基本原理"><a href="#7-2-1-RAG-的基本原理" class="headerlink" title="7.2.1 RAG 的基本原理"></a>7.2.1 RAG 的基本原理</h3><p>大语言模型（LLM）在生成内容时，虽然具备强大的语言理解和生成能力，但也面临着一些挑战。例如，LLM有时会生成不准确或误导性的内容，这被称为大模型“幻觉”。此外，模型所依赖的训练数据可能过时，尤其在面对最新的信息时，生成结果的准确性和时效性难以保证。对于特定领域的专业知识，LLM 的处理效率也较低，无法深入理解复杂的领域知识。因此，如何提升大模型的生成质量和效率，成为了当前研究的重要方向。</p>
<p>在这样的背景下，检索增强生成（Retrieval-Augmented Generation，RAG）技术应运而生，成为AI领域中的一大创新趋势。RAG 在生成答案之前，首先从外部的大规模文档数据库中检索出相关信息，并将这些信息融入到生成过程之中，从而指导和优化语言模型的输出。这一流程不仅极大地提升了内容生成的准确性和相关性，还使得生成的内容更加符合实时性要求。</p>
<p>RAG 的核心原理在于将“检索”与“生成”结合：当用户提出查询时，系统首先通过检索模块找到与问题相关的文本片段，然后将这些片段作为附加信息传递给语言模型，模型据此生成更为精准和可靠的回答。通过这种方式，RAG 有效缓解了大语言模型的“幻觉”问题，因为生成的内容建立在真实文档的基础上，使得答案更具可追溯性和可信度。同时，由于引入了最新的信息源，RAG 技术大大加快了知识更新速度，使得系统可以及时吸收和反映最新的领域动态。</p>
<h3 id="7-2-2-搭建一个-RAG-框架"><a href="#7-2-2-搭建一个-RAG-框架" class="headerlink" title="7.2.2 搭建一个 RAG 框架"></a>7.2.2 搭建一个 RAG 框架</h3><p>接下来我会带领大家一步一步实现一个简单的RAG模型，这个模型是基于RAG的一个简化版本，我们称之为 Tiny-RAG 。Tiny-RAG只保留了 RAG 的核心功能，即检索和生成，其目的是帮助大家更好地理解 RAG 模型的原理和实现。</p>
<h4 id="Step-1-RAG流程介绍"><a href="#Step-1-RAG流程介绍" class="headerlink" title="Step 1: RAG流程介绍"></a>Step 1: RAG流程介绍</h4><p>RAG通过在语言模型生成答案之前，先从广泛的文档数据库中检索相关信息，然后利用这些信息来引导生成过程，从而极大地提升了内容的准确性和相关性。RAG有效地缓解了幻觉问题，提高了知识更新的速度，并增强了内容生成的可追溯性，使得大型语言模型在实际应用中变得更加实用和可信。</p>
<p>RAG的基本结构有哪些呢？</p>
<ul>
<li>向量化模块：用来将文档片段向量化。</li>
<li>文档加载和切分模块：用来加载文档并切分成文档片段。</li>
<li>数据库：存放文档片段及其对应的向量表示。</li>
<li>检索模块：根据 Query（问题）检索相关的文档片段。</li>
<li>大模型模块：根据检索到的文档回答用户的问题。</li>
</ul>
<p>上述也就是 TinyRAG 的所有模块内容，如图7.5所示。</p>
<div align='center'>
    <img src="../images/7-images/7-2-tinyrag.png" alt="alt text" width="90%">
    <p>图7.5 TinyRAG 项目结构</p>
</div>

<p>接下来，让我们梳理一下RAG的流程是什么样的呢？</p>
<ul>
<li><strong>索引</strong>：将文档库分割成较短的片段，并通过编码器构建向量索引。</li>
<li><strong>检索</strong>：根据问题和片段的相似度检索相关文档片段。</li>
<li><strong>生成</strong>：以检索到的上下文为条件，生成问题的回答。</li>
</ul>
<p>如下图7.6所示的流程图，图片出处 <em><strong><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.10997.pdf">Retrieval-Augmented Generation for Large Language Models: A Survey</a></strong></em></p>
<div align='center'>
    <img src="../images/7-images/7-2-rag.png" alt="alt text" width="90%">
    <p>图7.6 RAG 流程图</p>
</div>

<h4 id="Step-2-向量化"><a href="#Step-2-向量化" class="headerlink" title="Step 2: 向量化"></a>Step 2: 向量化</h4><p>首先我们来动手实现一个向量化的类，这是RAG架构的基础。向量化类主要用来将文档片段向量化，将一段文本映射为一个向量。</p>
<p>首先我们要设置一个 <code>BaseEmbeddings</code> 基类，这样我们在使用其他模型时，只需要继承这个基类，然后在此基础上进行修改即可，方便代码扩展。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseEmbeddings</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Base class for embeddings</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path: <span class="built_in">str</span>, is_api: <span class="built_in">bool</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.path = path</span><br><span class="line">        <span class="variable language_">self</span>.is_api = is_api</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_embedding</span>(<span class="params">self, text: <span class="built_in">str</span>, model: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">float</span>]:</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cosine_similarity</span>(<span class="params">cls, vector1: <span class="type">List</span>[<span class="built_in">float</span>], vector2: <span class="type">List</span>[<span class="built_in">float</span>]</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate cosine similarity between two vectors</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        dot_product = np.dot(vector1, vector2)</span><br><span class="line">        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> magnitude:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> dot_product / magnitude</span><br></pre></td></tr></table></figure>

<p><code>BaseEmbeddings</code>基类有两个主要方法：<code>get_embedding</code>和<code>cosine_similarity</code>。<code>get_embedding</code>用于获取文本的向量表示，<code>cosine_similarity</code>用于计算两个向量之间的余弦相似度。在初始化类时设置了模型的路径和是否是API模型，例如使用OpenAI的Embedding API需要设置<code>self.is_api=True</code>。</p>
<p>继承<code>BaseEmbeddings</code>类只需要实现<code>get_embedding</code>方法，<code>cosine_similarity</code>方法会被继承下来。这就是编写基类的好处。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">OpenAIEmbedding</span>(<span class="title class_ inherited__">BaseEmbeddings</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    class for OpenAI embeddings</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path: <span class="built_in">str</span> = <span class="string">&#x27;&#x27;</span>, is_api: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__(path, is_api)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_api:</span><br><span class="line">            <span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line">            <span class="variable language_">self</span>.client = OpenAI()</span><br><span class="line">            <span class="variable language_">self</span>.client.api_key = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.client.base_url = os.getenv(<span class="string">&quot;OPENAI_BASE_URL&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_embedding</span>(<span class="params">self, text: <span class="built_in">str</span>, model: <span class="built_in">str</span> = <span class="string">&quot;text-embedding-3-large&quot;</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">float</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_api:</span><br><span class="line">            text = text.replace(<span class="string">&quot;\n&quot;</span>, <span class="string">&quot; &quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.client.embeddings.create(<span class="built_in">input</span>=[text], model=model).data[<span class="number">0</span>].embedding</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>

<h4 id="Step-3-文档加载和切分"><a href="#Step-3-文档加载和切分" class="headerlink" title="Step 3: 文档加载和切分"></a>Step 3: 文档加载和切分</h4><p>接下来我们来实现一个文档加载和切分的类，这个类主要用于加载文档并将其切分成文档片段。</p>
<p>文档可以是文章、书籍、对话、代码等文本内容，例如pdf文件、md文件、txt文件等。完整代码可以在 <em><strong><a href="./RAG/utils.py">RAG&#x2F;utils.py</a></strong></em> 文件中找到。该代码支持加载pdf、md、txt等类型的文件，只需编写相应的函数即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_file_content</span>(<span class="params">cls, file_path: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="comment"># 根据文件扩展名选择读取方法</span></span><br><span class="line">    <span class="keyword">if</span> file_path.endswith(<span class="string">&#x27;.pdf&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> cls.read_pdf(file_path)</span><br><span class="line">    <span class="keyword">elif</span> file_path.endswith(<span class="string">&#x27;.md&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> cls.read_markdown(file_path)</span><br><span class="line">    <span class="keyword">elif</span> file_path.endswith(<span class="string">&#x27;.txt&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> cls.read_text(file_path)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Unsupported file type&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>文档读取后需要进行切分。我们可以设置一个最大的Token长度，然后根据这个最大长度来切分文档。切分文档时最好以句子为单位（按<code>\n</code>粗切分），并保证片段之间有一些重叠内容，以提高检索的准确性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_chunk</span>(<span class="params">cls, text: <span class="built_in">str</span>, max_token_len: <span class="built_in">int</span> = <span class="number">600</span>, cover_content: <span class="built_in">int</span> = <span class="number">150</span></span>):</span><br><span class="line">    chunk_text = []</span><br><span class="line"></span><br><span class="line">    curr_len = <span class="number">0</span></span><br><span class="line">    curr_chunk = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    lines = text.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        line = line.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        line_len = <span class="built_in">len</span>(enc.encode(line))</span><br><span class="line">        <span class="keyword">if</span> line_len &gt; max_token_len:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;warning line_len = &#x27;</span>, line_len)</span><br><span class="line">        <span class="keyword">if</span> curr_len + line_len &lt;= max_token_len:</span><br><span class="line">            curr_chunk += line</span><br><span class="line">            curr_chunk += <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">            curr_len += line_len</span><br><span class="line">            curr_len += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            chunk_text.append(curr_chunk)</span><br><span class="line">            curr_chunk = curr_chunk[-cover_content:] + line</span><br><span class="line">            curr_len = line_len + cover_content</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> curr_chunk:</span><br><span class="line">        chunk_text.append(curr_chunk)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> chunk_text</span><br></pre></td></tr></table></figure>

<h4 id="Step-4-数据库与向量检索"><a href="#Step-4-数据库与向量检索" class="headerlink" title="Step 4: 数据库与向量检索"></a>Step 4: 数据库与向量检索</h4><p>完成文档切分和Embedding模型加载后，需要设计一个向量数据库来存放文档片段和对应的向量表示，以及设计一个检索模块用于根据Query检索相关文档片段。</p>
<p>向量数据库的功能包括：</p>
<ul>
<li><code>persist</code>：数据库持久化保存。</li>
<li><code>load_vector</code>：从本地加载数据库。</li>
<li><code>get_vector</code>：获取文档的向量表示。</li>
<li><code>query</code>：根据问题检索相关文档片段。</li>
</ul>
<p>完整代码可以在 <em><strong><a href="RAG/VectorBase.py">RAG&#x2F;VectorBase.py</a></strong></em> 文件中找到。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VectorStore</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, document: <span class="type">List</span>[<span class="built_in">str</span>] = [<span class="string">&#x27;&#x27;</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.document = document</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_vector</span>(<span class="params">self, EmbeddingModel: BaseEmbeddings</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]]:</span><br><span class="line">        <span class="comment"># 获得文档的向量表示</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">persist</span>(<span class="params">self, path: <span class="built_in">str</span> = <span class="string">&#x27;storage&#x27;</span></span>):</span><br><span class="line">        <span class="comment"># 数据库持久化保存</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_vector</span>(<span class="params">self, path: <span class="built_in">str</span> = <span class="string">&#x27;storage&#x27;</span></span>):</span><br><span class="line">        <span class="comment"># 从本地加载数据库</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">query</span>(<span class="params">self, query: <span class="built_in">str</span>, EmbeddingModel: BaseEmbeddings, k: <span class="built_in">int</span> = <span class="number">1</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="comment"># 根据问题检索相关文档片段</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p><code>query</code> 方法用于将用户提出的问题向量化，然后在数据库中检索相关文档片段并返回结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">query</span>(<span class="params">self, query: <span class="built_in">str</span>, EmbeddingModel: BaseEmbeddings, k: <span class="built_in">int</span> = <span class="number">1</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">    query_vector = EmbeddingModel.get_embedding(query)</span><br><span class="line">    result = np.array([<span class="variable language_">self</span>.get_similarity(query_vector, vector) <span class="keyword">for</span> vector <span class="keyword">in</span> <span class="variable language_">self</span>.vectors])</span><br><span class="line">    <span class="keyword">return</span> np.array(<span class="variable language_">self</span>.document)[result.argsort()[-k:][::-<span class="number">1</span>]].tolist()</span><br></pre></td></tr></table></figure>

<h4 id="Step-5-大模型模块"><a href="#Step-5-大模型模块" class="headerlink" title="Step 5: 大模型模块"></a>Step 5: 大模型模块</h4><p>接下来是大模型模块，用于根据检索到的文档回答用户的问题。</p>
<p>首先实现一个基类，这样可以方便扩展其他模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseModel</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path: <span class="built_in">str</span> = <span class="string">&#x27;&#x27;</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.path = path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">self, prompt: <span class="built_in">str</span>, history: <span class="type">List</span>[<span class="built_in">dict</span>], content: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p><code>BaseModel</code> 包含两个方法：<code>chat</code>和<code>load_model</code>。对于本地化运行的开源模型需要实现<code>load_model</code>，而API模型则不需要。</p>
<p>下面以 <em><strong><a target="_blank" rel="noopener" href="https://huggingface.co/internlm/internlm2-chat-7b">InternLM2-chat-7B</a></strong></em> 模型为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InternLMChat</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path: <span class="built_in">str</span> = <span class="string">&#x27;&#x27;</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__(path)</span><br><span class="line">        <span class="variable language_">self</span>.load_model()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">self, prompt: <span class="built_in">str</span>, history: <span class="type">List</span> = [], content: <span class="built_in">str</span>=<span class="string">&#x27;&#x27;</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        prompt = PROMPT_TEMPLATE[<span class="string">&#x27;InternLM_PROMPT_TEMPLATE&#x27;</span>].<span class="built_in">format</span>(question=prompt, context=content)</span><br><span class="line">        response, history = <span class="variable language_">self</span>.model.chat(<span class="variable language_">self</span>.tokenizer, prompt, history)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">import</span> torch</span><br><span class="line">        <span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = AutoTokenizer.from_pretrained(<span class="variable language_">self</span>.path, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">        <span class="variable language_">self</span>.model = AutoModelForCausalLM.from_pretrained(<span class="variable language_">self</span>.path, torch_dtype=torch.float16, trust_remote_code=<span class="literal">True</span>).cuda()</span><br></pre></td></tr></table></figure>

<p>可以用一个字典来保存所有的prompt，方便维护：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PROMPT_TEMPLATE = <span class="built_in">dict</span>(</span><br><span class="line">    InternLM_PROMPT_TEMPLATE=<span class="string">&quot;&quot;&quot;先对上下文进行内容总结,再使用上下文来回答用户的问题。如果你不知道答案，就说你不知道。总是使用中文回答。</span></span><br><span class="line"><span class="string">        问题: &#123;question&#125;</span></span><br><span class="line"><span class="string">        可参考的上下文：</span></span><br><span class="line"><span class="string">        ···</span></span><br><span class="line"><span class="string">        &#123;context&#125;</span></span><br><span class="line"><span class="string">        ···</span></span><br><span class="line"><span class="string">        如果给定的上下文无法让你做出回答，请回答数据库中没有这个内容，你不知道。</span></span><br><span class="line"><span class="string">        有用的回答:&quot;&quot;&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这样我们就可以利用InternLM2模型来做RAG啦！</p>
<h4 id="Step-6-Tiny-RAG-Demo"><a href="#Step-6-Tiny-RAG-Demo" class="headerlink" title="Step 6: Tiny-RAG Demo"></a>Step 6: Tiny-RAG Demo</h4><p>接下来，我们来看看Tiny-RAG的Demo吧！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> RAG.VectorBase <span class="keyword">import</span> VectorStore</span><br><span class="line"><span class="keyword">from</span> RAG.utils <span class="keyword">import</span> ReadFiles</span><br><span class="line"><span class="keyword">from</span> RAG.LLM <span class="keyword">import</span> OpenAIChat, InternLMChat</span><br><span class="line"><span class="keyword">from</span> RAG.Embeddings <span class="keyword">import</span> JinaEmbedding, ZhipuEmbedding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没有保存数据库</span></span><br><span class="line">docs = ReadFiles(<span class="string">&#x27;./data&#x27;</span>).get_content(max_token_len=<span class="number">600</span>, cover_content=<span class="number">150</span>) <span class="comment"># 获取data目录下的所有文件内容并分割</span></span><br><span class="line">vector = VectorStore(docs)</span><br><span class="line">embedding = ZhipuEmbedding() <span class="comment"># 创建EmbeddingModel</span></span><br><span class="line">vector.get_vector(EmbeddingModel=embedding)</span><br><span class="line">vector.persist(path=<span class="string">&#x27;storage&#x27;</span>) <span class="comment"># 将向量和文档内容保存到storage目录，下次再用可以直接加载本地数据库</span></span><br><span class="line"></span><br><span class="line">question = <span class="string">&#x27;git的原理是什么？&#x27;</span></span><br><span class="line"></span><br><span class="line">content = vector.query(question, model=<span class="string">&#x27;zhipu&#x27;</span>, k=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">chat = InternLMChat(path=<span class="string">&#x27;model_path&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(chat.chat(question, [], content))</span><br></pre></td></tr></table></figure>

<p>也可以从本地加载已处理好的数据库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> RAG.VectorBase <span class="keyword">import</span> VectorStore</span><br><span class="line"><span class="keyword">from</span> RAG.utils <span class="keyword">import</span> ReadFiles</span><br><span class="line"><span class="keyword">from</span> RAG.LLM <span class="keyword">import</span> OpenAIChat, InternLMChat</span><br><span class="line"><span class="keyword">from</span> RAG.Embeddings <span class="keyword">import</span> JinaEmbedding, ZhipuEmbedding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存数据库之后</span></span><br><span class="line">vector = VectorStore()</span><br><span class="line"></span><br><span class="line">vector.load_vector(<span class="string">&#x27;./storage&#x27;</span>) <span class="comment"># 加载本地数据库</span></span><br><span class="line"></span><br><span class="line">question = <span class="string">&#x27;git的原理是什么？&#x27;</span></span><br><span class="line"></span><br><span class="line">embedding = ZhipuEmbedding() <span class="comment"># 创建EmbeddingModel</span></span><br><span class="line"></span><br><span class="line">content = vector.query(question, EmbeddingModel=embedding, k=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">chat = InternLMChat(path=<span class="string">&#x27;model_path&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(chat.chat(question, [], content))</span><br></pre></td></tr></table></figure>

<h2 id="7-3-Agent"><a href="#7-3-Agent" class="headerlink" title="7.3 Agent"></a>7.3 Agent</h2><h3 id="7-3-1-什么是-LLM-Agent？"><a href="#7-3-1-什么是-LLM-Agent？" class="headerlink" title="7.3.1 什么是 LLM Agent？"></a>7.3.1 什么是 LLM Agent？</h3><p>简单来说，大模型Agent是一个以LLM为核心“大脑”，并赋予其自主规划、记忆和使用工具能力的系统。 它不再仅仅是被动地响应用户的提示（Prompt），而是能够：</p>
<ol>
<li>理解目标（Goal Understanding）： 接收一个相对复杂或高层次的目标（例如，“帮我规划一个周末去北京的旅游行程并预订机票酒店”）。</li>
<li>自主规划（Planning）： 将大目标分解成一系列可执行的小步骤（例如，“搜索北京景点”、“查询天气”、“比较机票价格”、“查找合适的酒店”、“调用预订API”等）。</li>
<li>记忆（Memory）： 拥有短期记忆（记住当前任务的上下文）和长期记忆（从过去的交互或外部知识库中学习和检索信息）。</li>
<li>工具使用（Tool Use）： 调用外部API、插件或代码执行环境来获取信息（如搜索引擎、数据库）、执行操作（如发送邮件、预订服务）或进行计算。</li>
<li>反思与迭代（Reflection &amp; Iteration）： （在更高级的Agent中）能够评估自己的行为和结果，从中学习并调整后续计划。</li>
</ol>
<p>传统的LLM像一个知识渊博但只能纸上谈兵的图书馆员，而 LLM Agent 则更像一个全能的私人助理，不仅懂得多，还能跑腿办事，甚至能主动思考最优方案。</p>
<div align='center'>
    <img src="../images/7-images/7-3-Agent工作原理.png" alt="alt text" width="90%">
    <p>图7.7 Agent 工作原理</p>
</div>

<p>LLM Agent 通过将大型语言模型的强大语言理解和生成能力与规划、记忆和工具使用等关键模块相结合，实现了超越传统大模型的自主性和复杂任务处理能力，这种能力使得 LLM Agent 在许多垂直领域（如法律、医疗、金融等）都具有广泛的应用潜力，如图7.7所示 Agent 工作原理。</p>
<h3 id="7-3-2-LLM-Agent-的类型"><a href="#7-3-2-LLM-Agent-的类型" class="headerlink" title="7.3.2 LLM Agent 的类型"></a>7.3.2 LLM Agent 的类型</h3><p>虽然LLM Agent的概念还在快速发展中，但根据其设计理念和能力侧重，我们可以大致将其分为几类：</p>
<p>任务导向型Agent（Task-Oriented Agents）：</p>
<ul>
<li>特点： 专注于完成特定领域的、定义明确的任务，例如客户服务、代码生成、数据分析等。</li>
<li>工作方式： 通常有预设的流程和可调用的特定工具集。LLM主要负责理解用户意图、填充任务槽位、生成回应或调用合适- 的工具。</li>
<li>例子： 专门用于预订餐厅的聊天机器人、辅助编程的代码助手（如GitHub Copilot在某些高级功能上体现了Agent特性）。</li>
</ul>
<p>规划与推理型Agent（Planning &amp; Reasoning Agents）：</p>
<ul>
<li>特点： 强调自主分解复杂任务、制定多步计划，并根据环境反馈进行调整的能力。它们通常需要更强的推理能力。</li>
<li>工作方式： 常采用特定的思维框架，如ReAct (Reason+Act)，让模型先进行“思考”（Reasoning）分析当前情况和所需行动，然后执行“行动”（Action）调用工具，再根据工具返回结果进行下一轮思考。Chain-of-Thought (CoT) 等提示工程技术也是其推理的基础。</li>
<li>例子： 需要整合网络搜索、计算器、数据库查询等多种工具来回答复杂问题的研究型Agent，或者能够自主完成“写一篇关于XX主题的报告，并配上相关数据图表”这类任务的Agent。</li>
</ul>
<p>多Agent系统（Multi-Agent Systems）：</p>
<ul>
<li>特点： 由多个具有不同角色或能力的Agent协同工作，共同完成一个更宏大的目标。</li>
<li>工作方式： Agent之间可以进行通信、协作、辩论甚至竞争。例如，一个Agent负责规划，一个负责执行，一个负责审查。</li>
<li>例子： 模拟软件开发团队（产品经理Agent、程序员Agent、测试员Agent）来自动生成和测试代码；模拟一个公司组织结构来完成商业策划。AutoGen、ChatDev等框架支持这类系统的构建。</li>
</ul>
<p>探索与学习型Agent（Exploration &amp; Learning Agents）：</p>
<ul>
<li>特点： 这类Agent不仅执行任务，还能在与环境的交互中主动学习新知识、新技能或优化自身策略，类似于强化学习中的Agent概念。</li>
<li>工作方式： 可能包含更复杂的记忆和反思机制，能够根据成功或失败的经验调整未来的规划和行动。</li>
<li>例子： 能在未知软件环境中自主探索学习如何操作的Agent，或者在玩游戏时不断提升策略的Agent。</li>
</ul>
<h3 id="7-3-3-动手构造一个-Tiny-Agent"><a href="#7-3-3-动手构造一个-Tiny-Agent" class="headerlink" title="7.3.3 动手构造一个 Tiny-Agent"></a>7.3.3 动手构造一个 Tiny-Agent</h3><p>我们来基于 <code>openai</code> 库和其 <code>tool_calls</code> 功能，动手构造一个 Tiny-Agent，这个 Agent 是一个简单的任务导向型 Agent，它能够根据用户的输入，回答一些简单的问题。</p>
<p>最终的实现效果如图7.8所示：</p>
<div align='center'>
    <img src="../images/7-images/7-3-tinyagent-example.png" style="width: 100%;">
    <p>图7.8 效果示意图</p>
</div>

<h4 id="Step-1-初始化客户端和模型"><a href="#Step-1-初始化客户端和模型" class="headerlink" title="Step 1 : 初始化客户端和模型"></a>Step 1 : 初始化客户端和模型</h4><p>首先，我们需要一个能够调用大模型的客户端。这里我们使用 <code>openai</code> 库，并配置其指向一个兼容 OpenAI API 的服务终端，例如 <a target="_blank" rel="noopener" href="https://cloud.siliconflow.cn/i/ybUFvmqK">SiliconFlow</a>。同时，指定要使用的模型，如 <code>Qwen/Qwen2.5-32B-Instruct</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 OpenAI 客户端</span></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;YOUR_API_KEY&quot;</span>,  <span class="comment"># 替换为你的 API Key</span></span><br><span class="line">    base_url=<span class="string">&quot;https://api.siliconflow.cn/v1&quot;</span>, <span class="comment"># 使用 SiliconFlow 的 API 地址</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定模型名称</span></span><br><span class="line">model_name = <span class="string">&quot;Qwen/Qwen2.5-32B-Instruct&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意:</strong> 你需要将 <code>YOUR_API_KEY</code> 替换为你从 <a target="_blank" rel="noopener" href="https://cloud.siliconflow.cn/i/ybUFvmqK">SiliconFlow</a> 或其他服务商获取的有效 API Key。</p>
</blockquote>
<h4 id="Step-2-定义工具函数"><a href="#Step-2-定义工具函数" class="headerlink" title="Step 2: 定义工具函数"></a>Step 2: 定义工具函数</h4><p>我们在 <code>src/tools.py</code> 文件中定义 Agent 可以使用的工具函数。每个函数都需要有清晰的文档字符串（docstring），描述其功能和参数，因为这将用于自动生成工具的 JSON Schema。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># src/tools.py</span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取当前日期和时间</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_datetime</span>() -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取当前日期和时间。</span></span><br><span class="line"><span class="string">    :return: 当前日期和时间的字符串表示。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    current_datetime = datetime.now()</span><br><span class="line">    formatted_datetime = current_datetime.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> formatted_datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="built_in">float</span>, b: <span class="built_in">float</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算两个浮点数的和。</span></span><br><span class="line"><span class="string">    :param a: 第一个浮点数。</span></span><br><span class="line"><span class="string">    :param b: 第二个浮点数。</span></span><br><span class="line"><span class="string">    :return: 两个浮点数的和。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(a + b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare</span>(<span class="params">a: <span class="built_in">float</span>, b: <span class="built_in">float</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    比较两个浮点数的大小。</span></span><br><span class="line"><span class="string">    :param a: 第一个浮点数。</span></span><br><span class="line"><span class="string">    :param b: 第二个浮点数。</span></span><br><span class="line"><span class="string">    :return: 比较结果的字符串表示。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> a &gt; b:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;<span class="subst">&#123;a&#125;</span> is greater than <span class="subst">&#123;b&#125;</span>&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> a &lt; b:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;<span class="subst">&#123;b&#125;</span> is greater than <span class="subst">&#123;a&#125;</span>&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;<span class="subst">&#123;a&#125;</span> is equal to <span class="subst">&#123;b&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_letter_in_string</span>(<span class="params">a: <span class="built_in">str</span>, b: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    统计字符串中某个字母的出现次数。</span></span><br><span class="line"><span class="string">    :param a: 要搜索的字符串。</span></span><br><span class="line"><span class="string">    :param b: 要统计的字母。</span></span><br><span class="line"><span class="string">    :return: 字母在字符串中出现的次数。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(a.count(b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ... (可能还有其他工具函数)</span></span><br></pre></td></tr></table></figure>

<p>为了让 OpenAI API 理解这些工具，我们需要将它们转换成特定的 JSON Schema 格式。这可以通过 <code>src/utils.py</code> 中的 <code>function_to_json</code> 辅助函数完成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># src/utils.py (部分)</span></span><br><span class="line"><span class="keyword">import</span> inspect</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">function_to_json</span>(<span class="params">func</span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="comment"># ... (函数实现细节)</span></span><br><span class="line">    <span class="comment"># 返回符合 OpenAI tool schema 的字典</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: func.__name__,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: inspect.getdoc(func),</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: parameters,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: required,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h4 id="Step-3-构造-Agent-类"><a href="#Step-3-构造-Agent-类" class="headerlink" title="Step 3: 构造 Agent 类"></a>Step 3: 构造 Agent 类</h4><p>我们在 <code>src/core.py</code> 文件中定义 <code>Agent</code> 类。这个类负责管理对话历史、调用 OpenAI API、处理工具调用请求以及执行工具函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># src/core.py (部分)</span></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Dict</span>, <span class="type">Any</span></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> function_to_json</span><br><span class="line"><span class="comment"># 导入定义好的工具函数</span></span><br><span class="line"><span class="keyword">from</span> tools <span class="keyword">import</span> get_current_datetime, add, compare, count_letter_in_string</span><br><span class="line"></span><br><span class="line">SYSREM_PROMPT = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个叫不要葱姜蒜的人工智能助手。你的输出应该与用户的语言保持一致。</span></span><br><span class="line"><span class="string">当用户的问题需要调用工具时，你可以从提供的工具列表中调用适当的工具函数。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Agent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, client: OpenAI, model: <span class="built_in">str</span> = <span class="string">&quot;Qwen/Qwen2.5-32B-Instruct&quot;</span>, tools: <span class="type">List</span>=[], verbose : <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.client = client</span><br><span class="line">        <span class="variable language_">self</span>.tools = tools</span><br><span class="line">        <span class="variable language_">self</span>.model = model</span><br><span class="line">        <span class="variable language_">self</span>.messages = [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: SYSREM_PROMPT&#125;,</span><br><span class="line">        ]</span><br><span class="line">        <span class="variable language_">self</span>.verbose = verbose</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_tool_schema</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]]:</span><br><span class="line">        <span class="comment"># 获取所有工具的 JSON 模式</span></span><br><span class="line">        <span class="keyword">return</span> [function_to_json(tool) <span class="keyword">for</span> tool <span class="keyword">in</span> <span class="variable language_">self</span>.tools]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">handle_tool_call</span>(<span class="params">self, tool_call</span>):</span><br><span class="line">        <span class="comment"># 处理工具调用</span></span><br><span class="line">        function_name = tool_call.function.name</span><br><span class="line">        function_args = tool_call.function.arguments</span><br><span class="line">        function_id = tool_call.<span class="built_in">id</span></span><br><span class="line"></span><br><span class="line">        function_call_content = <span class="built_in">eval</span>(<span class="string">f&quot;<span class="subst">&#123;function_name&#125;</span>(**<span class="subst">&#123;function_args&#125;</span>)&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: function_call_content,</span><br><span class="line">            <span class="string">&quot;tool_call_id&quot;</span>: function_id,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_completion</span>(<span class="params">self, prompt</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取模型的完成响应</span></span><br><span class="line">        response = <span class="variable language_">self</span>.client.chat.completions.create(</span><br><span class="line">            model=<span class="variable language_">self</span>.model,</span><br><span class="line">            messages=<span class="variable language_">self</span>.messages,</span><br><span class="line">            tools=<span class="variable language_">self</span>.get_tool_schema(),</span><br><span class="line">            stream=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检查模型是否调用了工具        </span></span><br><span class="line">        <span class="keyword">if</span> response.choices[<span class="number">0</span>].message.tool_calls:</span><br><span class="line">            <span class="variable language_">self</span>.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response.choices[<span class="number">0</span>].message.content&#125;)</span><br><span class="line">            <span class="comment"># 处理工具调用</span></span><br><span class="line">            tool_list = []</span><br><span class="line">            <span class="keyword">for</span> tool_call <span class="keyword">in</span> response.choices[<span class="number">0</span>].message.tool_calls:</span><br><span class="line">                <span class="comment"># 处理工具调用并将结果添加到消息列表中</span></span><br><span class="line">                <span class="variable language_">self</span>.messages.append(<span class="variable language_">self</span>.handle_tool_call(tool_call))</span><br><span class="line">                tool_list.append([tool_call.function.name, tool_call.function.arguments])</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.verbose:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;调用工具：&quot;</span>, response.choices[<span class="number">0</span>].message.content, tool_list)</span><br><span class="line">            <span class="comment"># 再次获取模型的完成响应，这次包含工具调用的结果</span></span><br><span class="line">            response = <span class="variable language_">self</span>.client.chat.completions.create(</span><br><span class="line">                model=<span class="variable language_">self</span>.model,</span><br><span class="line">                messages=<span class="variable language_">self</span>.messages,</span><br><span class="line">                tools=<span class="variable language_">self</span>.get_tool_schema(),</span><br><span class="line">                stream=<span class="literal">False</span>,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将模型的完成响应添加到消息列表中</span></span><br><span class="line">        <span class="variable language_">self</span>.messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: response.choices[<span class="number">0</span>].message.content&#125;)</span><br><span class="line">        <span class="keyword">return</span> response.choices[<span class="number">0</span>].message.content</span><br></pre></td></tr></table></figure>

<p>Agent 的工作流程如下：</p>
<ol>
<li>接收用户输入。</li>
<li>调用大模型（如 Qwen），并告知其可用的工具及其 Schema。</li>
<li>如果模型决定调用工具，Agent 会解析请求，执行相应的 Python 函数。</li>
<li>Agent 将工具的执行结果返回给模型。</li>
<li>模型根据工具结果生成最终回复。</li>
<li>Agent 将最终回复返回给用户。</li>
</ol>
<p>如图7.9所示，Agent 调用工具流程：</p>
<div align='center'>
    <img src="../images/7-images/7-3-Tiny_Agent.jpg" alt="alt text" width="80%">
    <p>图7.9 Agent 工作流程</p>
</div>

<h4 id="Step-4-运行-Agent"><a href="#Step-4-运行-Agent" class="headerlink" title="Step 4: 运行 Agent"></a>Step 4: 运行 Agent</h4><p>现在我们可以实例化并运行 Agent。在 <code>demo.py</code> 的 <code>if __name__ == &quot;__main__&quot;:</code> 部分提供了一个简单的命令行交互示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># demo.py (部分)</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    client = OpenAI(</span><br><span class="line">        api_key=<span class="string">&quot;YOUR_API_KEY&quot;</span>, <span class="comment"># 替换为你的 API Key</span></span><br><span class="line">        base_url=<span class="string">&quot;https://api.siliconflow.cn/v1&quot;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建 Agent 实例，传入 client、模型名称和工具函数列表</span></span><br><span class="line">    agent = Agent(</span><br><span class="line">        client=client,</span><br><span class="line">        model=<span class="string">&quot;Qwen/Qwen2.5-32B-Instruct&quot;</span>,</span><br><span class="line">        tools=[get_current_datetime, add, compare, count_letter_in_string],</span><br><span class="line">        verbose=<span class="literal">True</span> <span class="comment"># 设置为 True 可以看到工具调用信息</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始交互式对话循环</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 使用彩色输出区分用户输入和AI回答</span></span><br><span class="line">        prompt = <span class="built_in">input</span>(<span class="string">&quot;\033[94mUser: \033[0m&quot;</span>)  <span class="comment"># 蓝色显示用户输入提示</span></span><br><span class="line">        <span class="keyword">if</span> prompt.lower() == <span class="string">&quot;exit&quot;</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        response = agent.get_completion(prompt)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[92mAssistant: \033[0m&quot;</span>, response)  <span class="comment"># 绿色显示AI助手回答</span></span><br></pre></td></tr></table></figure>

<p>运行 <code>python demo.py</code> 后，你可以开始提问。如果问题需要调用工具，Agent 会自动处理。</p>
<p><strong>示例交互:</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">User: 你好</span><br><span class="line">Assistant:  你好！有什么可以帮助你的吗？</span><br><span class="line">User: 9.12和9 .2哪个更大？</span><br><span class="line">调用工具： [<span class="string">&#x27;compare&#x27;</span>]</span><br><span class="line">Assistant:  9.2 比 9.12 更大。</span><br><span class="line">User: 为什么？</span><br><span class="line">Assistant:  当我们比较9.12和9.2时，可以将它们看作是9.12和9.20。由于9.20在小数点后第二位是0，而9.12在小数点后第二位是2，所以在小数点后第一位相等的情况下，9.20（即9.2）大于9.12。因此，9.2 比 9.12 更大。</span><br><span class="line">User: strawberry中有几个r？</span><br><span class="line">调用工具： [<span class="string">&#x27;count_letter_in_string&#x27;</span>]</span><br><span class="line">Assistant:  单词 <span class="string">&quot;strawberry&quot;</span> 中有3个字母 <span class="string">&#x27;r&#x27;</span>。</span><br><span class="line">User: 你确信嘛？</span><br><span class="line">调用工具： [<span class="string">&#x27;count_letter_in_string&#x27;</span>]</span><br><span class="line">Assistant:  是的，我确定。单词 <span class="string">&quot;strawberry&quot;</span> 中确实有3个字母 <span class="string">&#x27;r&#x27;</span>。让我们再次确认一下，<span class="string">&quot;strawberry&quot;</span> 中的 <span class="string">&#x27;r&#x27;</span> 确实出现了3次。</span><br><span class="line">User: 好的 你很薄，现在几点 了？</span><br><span class="line">调用工具： [<span class="string">&#x27;get_current_datetime&#x27;</span>]</span><br><span class="line">Assistant:  当前的时间是2025年4月26日17:01:33。不过，我注意到您提到“你很薄”，这似乎是一个打字错误，如果您有任何其他问题或者需要进一步的帮助，请告诉我！</span><br><span class="line">User: <span class="built_in">exit</span></span><br></pre></td></tr></table></figure>

<p><strong>参考文献</strong></p>
<p>[1] Hugging Face. (2023). <em>Open LLM Leaderboard: 开源大语言模型基准测试平台</em>. <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard">https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard</a>  </p>
<p>[2] awacke1. (2023). <em>LMSYS Chatbot Arena Leaderboard: 大型语言模型竞技场评估平台</em>. <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/awacke1/lmsys-chatbot-arena-leaderboard">https://huggingface.co/spaces/awacke1/lmsys-chatbot-arena-leaderboard</a>  </p>
<p>[3] OpenCompass 团队. (2023). <em>OpenCompass: 大模型统一评测平台</em>. <a target="_blank" rel="noopener" href="https://rank.opencompass.org.cn/home">https://rank.opencompass.org.cn/home</a>  </p>
<p>[4] OpenCompass 金融榜团队. (2024). <em>CFBENCHMARK: 金融领域大模型评测榜单</em>. <a target="_blank" rel="noopener" href="https://specialist.opencompass.org.cn/CFBenchmark">https://specialist.opencompass.org.cn/CFBenchmark</a>  </p>
<p>[5] OpenCompass 安全榜团队. (2024). <em>Flames: 大模型安全评测榜单</em>. <a target="_blank" rel="noopener" href="https://flames.opencompass.org.cn/leaderboard">https://flames.opencompass.org.cn/leaderboard</a>  </p>
<p>[6] OpenCompass 通识榜团队. (2024). <em>BotChat: 大模型通用对话能力评测</em>. <a target="_blank" rel="noopener" href="https://botchat.opencompass.org.cn/">https://botchat.opencompass.org.cn/</a>  </p>
<p>[7] OpenCompass 法律榜团队. (2024). <em>LawBench: 法律领域大模型评测</em>. <a target="_blank" rel="noopener" href="https://lawbench.opencompass.org.cn/leaderboard">https://lawbench.opencompass.org.cn/leaderboard</a>  </p>
<p>[8] OpenCompass 医疗榜团队. (2024). <em>MedBench: 医疗领域大模型评测</em>. <a target="_blank" rel="noopener" href="https://medbench.opencompass.org.cn/leaderboard">https://medbench.opencompass.org.cn/leaderboard</a>  </p>
<p>[9] Zhi Jing, Yongye Su, and Yikun Han. (2024). <em>When Large Language Models Meet Vector Databases: A Survey.</em> arXiv preprint arXiv:2402.01763.</p>
<p>[10] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. (2024). <em>Retrieval-Augmented Generation for Large Language Models: A Survey.</em> arXiv preprint arXiv:2312.10997.</p>
<p>[11] Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez, 和 Graham Neubig. (2023). <em>Learning to Filter Context for Retrieval-Augmented Generation.</em> arXiv preprint arXiv:2311.08377.</p>
<p>[12] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown 和 Yoav Shoham. (2023). <em>In-Context Retrieval-Augmented Language Models.</em> arXiv preprint arXiv:2302.00083.</p>

        
      </div>

         
    </div>
    
     
  </div>
  
    
<nav id="article-nav">
  <a class="article-nav-btn left  disabled "
     >
    <i class="fa-solid fa-angle-left"></i>
    <p class="title-text">
        
    </p>
  </a>
  <a class="article-nav-btn right "
    
      href="/2025/06/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E5%AE%9E%E8%B7%B5/"
      title="大模型训练流程实践"
     >

    <p class="title-text">
      
        大模型训练流程实践
        
    </p>
    <i class="fa-solid fa-angle-right"></i>
  </a>
</nav>


  
</article>






    </div>
    <div id="footer-wrapper">
      <footer id="footer">
  
  <div id="footer-info" class="inner">
    
    &copy; 2025 Kouir Wu<br>
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & Theme <a target="_blank" rel="noopener" href="https://github.com/saicaca/hexo-theme-vivia">Vivia</a>
  </div>
</footer>

    </div>
    <div class="back-to-top-wrapper">
    <button id="back-to-top-btn" class="back-to-top-btn hide" onclick="topFunction()">
        <i class="fa-solid fa-angle-up"></i>
    </button>
</div>

<script>
    function topFunction() {
        window.scroll({ top: 0, behavior: 'smooth' });
    }
    let btn = document.getElementById('back-to-top-btn');
    function scrollFunction() {
        if (document.body.scrollTop > 600 || document.documentElement.scrollTop > 600) {
            btn.classList.remove('hide')
        } else {
            btn.classList.add('hide')
        }
    }
    window.onscroll = function() {
        scrollFunction();
    }
</script>

  </div>
  <script src="/js/light-dark-switch.js"></script>
</body>
</html>
